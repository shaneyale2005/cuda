{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d147f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile elementwise_fp32.cu\n",
    "#include <torch/extension.h>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "__global__ void elementwise_add_f32_kernel(const float* A, const float* B, float* C, int N) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < N) {\n",
    "        C[idx] = A[idx] + B[idx];\n",
    "    }\n",
    "}\n",
    "\n",
    "void elementwise_add_f32(torch::Tensor A, torch::Tensor B, torch::Tensor C) {\n",
    "    int N = A.numel();\n",
    "    int threads = 256;\n",
    "    int blocks = (N + threads - 1) / threads;\n",
    "    elementwise_add_f32_kernel<<<blocks, threads>>>(\n",
    "        A.data_ptr<float>(),\n",
    "        B.data_ptr<float>(),\n",
    "        C.data_ptr<float>(),\n",
    "        N\n",
    "    );\n",
    "}\n",
    "\n",
    "PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {\n",
    "    m.def(\"elementwise_add_f32\", &elementwise_add_f32, \"Elementwise Add f32\");\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8207c12",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 测试代码如下\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.cpp_extension import load\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# 编译并加载 CUDA 扩展\n",
    "lib = load(\n",
    "    name=\"elementwise_lib\",\n",
    "    sources=[\"elementwise_fp32.cu\"],\n",
    "    extra_cuda_cflags=[\"-O3\"],\n",
    "    extra_cflags=[\"-std=c++17\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "def run_benchmark(func, a, b, out=None, iters=1000):\n",
    "    # warmup\n",
    "    for _ in range(10):\n",
    "        func(a, b, out)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(iters):\n",
    "        func(a, b, out)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "\n",
    "    mean_time = (end - start) * 1000 / iters\n",
    "    print(f\"Time per call: {mean_time:.6f} ms\")\n",
    "\n",
    "# 测试数据\n",
    "N = 1024 * 1024  # 一百万个元素\n",
    "a = torch.randn(N, device=\"cuda\", dtype=torch.float32)\n",
    "b = torch.randn(N, device=\"cuda\", dtype=torch.float32)\n",
    "c = torch.zeros_like(a)\n",
    "\n",
    "# 跑自定义 kernel\n",
    "run_benchmark(lib.elementwise_add_f32, a, b, c)\n",
    "\n",
    "# 跑 PyTorch 内置加法\n",
    "run_benchmark(lambda x,y,z: torch.add(x,y,out=z), a, b, c)\n",
    "\n",
    "# 对比结果\n",
    "print(\"验证结果是否一致:\", torch.allclose(a+b, c))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
